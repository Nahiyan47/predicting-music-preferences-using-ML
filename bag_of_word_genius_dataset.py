# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EfeJYCUnObgpYNk4q_IWrqlP_GdSGTj4
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder

# Load the dataset
df = pd.read_csv("song_lyrics_genius.csv")

# Separate features and target
X = df.drop(columns=["tag"])  # Features
y = df["tag"]  # Target

# Encode target labels into integers
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Convert text data (lyrics) to numerical format using CountVectorizer (Bag of Words)
count_vectorizer = CountVectorizer(max_features=1000)  # You can adjust max_features as needed
X_train_bow = count_vectorizer.fit_transform(X_train["lyrics"].astype(str))
X_test_bow = count_vectorizer.transform(X_test["lyrics"].astype(str))

# Train an XGBoost classifier
model = XGBClassifier()
model.fit(X_train_bow, y_train)

# Predict on the test set
y_pred = model.predict(X_test_bow)

# Decode integer predictions back to original labels
y_pred_labels = label_encoder.inverse_transform(y_pred)
y_test_labels = label_encoder.inverse_transform(y_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy}")

# Classification report
print(classification_report(y_test, y_pred))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix')
plt.show()

# Feature importance plot
feature_names = count_vectorizer.get_feature_names_out()
feature_importance = model.feature_importances_
sorted_idx = feature_importance.argsort()[::-1][:20]  # Show top 20 important features
plt.figure(figsize=(10, 8))
sns.barplot(x=feature_importance[sorted_idx], y=[feature_names[i] for i in sorted_idx])
plt.xlabel('Feature Importance Score')
plt.ylabel('Feature Name')
plt.title('Top 20 Feature Importance')
plt.xticks(rotation=45)
plt.show()





